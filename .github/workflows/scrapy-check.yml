name: Scrapy check

on:
  push:

jobs:
  scrapy-check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Poetry
        uses: abatilo/actions-poetry@v3
        with:
          poetry-version: "2.1.4"

      - name: Install dependencies
        run: poetry install --no-interaction --no-root

      - name: Lint (ruff)
        run: poetry run ruff check .

      - name: Run scrapy check
        working-directory: horse_racing_crawler
        env:
          S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_REGION_NAME: ${{ secrets.S3_REGION_NAME }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          S3_HTTP_CACHE_PREFIX: ${{ secrets.S3_HTTP_CACHE_PREFIX }}
          S3_FEEDS_PREFIX: ${{ secrets.S3_FEEDS_PREFIX }}
        run: poetry run scrapy check NetkeibaSpider
